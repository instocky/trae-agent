# Provider Architecture Analysis

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ Trae Agent

### –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
LLMClient (Facade)
    ‚Üì
BaseLLMClient (Abstract Base Class)
    ‚Üì
[OpenAIClient, AnthropicClient, AzureClient] (Concrete Implementations)
```

## üìã –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1. **LLMProvider (Enum)**
```python
class LLMProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    AZURE = "azure"
    # üéØ GEMINI = "gemini"  # –î–æ–±–∞–≤–∏–º –∑–¥–µ—Å—å
```

### 2. **ModelParameters (Dataclass)**
```python
@dataclass
class ModelParameters:
    model: str                    # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    api_key: str                 # API –∫–ª—é—á
    max_tokens: int              # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
    temperature: float           # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    top_p: float                 # Top-p –ø–∞—Ä–∞–º–µ—Ç—Ä
    top_k: int                   # Top-k –ø–∞—Ä–∞–º–µ—Ç—Ä  
    parallel_tool_calls: bool    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    max_retries: int             # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤
    base_url: str | None = None  # –ë–∞–∑–æ–≤—ã–π URL
    api_version: str | None = None # –í–µ—Ä—Å–∏—è API
```

### 3. **BaseLLMClient (ABC)**
–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:

```python
class BaseLLMClient(ABC):
    def __init__(self, model_parameters: ModelParameters)
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
    @abstractmethod
    def set_chat_history(self, messages: list[LLMMessage]) -> None
    
    @abstractmethod  
    def chat(self, messages: list[LLMMessage], model_parameters: ModelParameters, 
             tools: list[Tool] | None = None, reuse_history: bool = True) -> LLMResponse
    
    @abstractmethod
    def supports_tool_calling(self, model_parameters: ModelParameters) -> bool
```

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö

### LLMMessage
```python
@dataclass
class LLMMessage:
    role: str                          # "system", "user", "assistant"
    content: str | None = None         # –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
    tool_call: ToolCall | None = None  # –í—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    tool_result: ToolResult | None = None # –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
```

### LLMResponse  
```python
@dataclass
class LLMResponse:
    content: str                       # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç
    usage: LLMUsage | None = None      # –ú–µ—Ç—Ä–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
    model: str | None = None           # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    finish_reason: str | None = None   # –ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    tool_calls: list[ToolCall] | None = None # –í—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
```

### LLMUsage
```python
@dataclass  
class LLMUsage:
    input_tokens: int                  # –¢–æ–∫–µ–Ω—ã –≤–≤–æ–¥–∞
    output_tokens: int                 # –¢–æ–∫–µ–Ω—ã –≤—ã–≤–æ–¥–∞
    cache_creation_input_tokens: int = 0
    cache_read_input_tokens: int = 0
    reasoning_tokens: int = 0          # –¢–æ–∫–µ–Ω—ã —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è
```

## üîß –ü–∞—Ç—Ç–µ—Ä–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

### –ü—Ä–∏–º–µ—Ä: OpenAIClient

1. **–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**
```python
def __init__(self, model_parameters: ModelParameters):
    super().__init__(model_parameters)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if self.api_key == "":
        self.api_key = os.getenv("OPENAI_API_KEY", "")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    self.client = openai.OpenAI(api_key=self.api_key)
    self.message_history = []
```

2. **–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π**
```python
def parse_messages(self, messages: list[LLMMessage]) -> ProviderFormat:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ LLMMessage –≤ —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ tool_calls, tool_results, –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
```

3. **–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ chat**
```python
def chat(self, messages: list[LLMMessage], model_parameters: ModelParameters, 
         tools: list[Tool] | None = None, reuse_history: bool = True) -> LLMResponse:
    
    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    provider_messages = self.parse_messages(messages)
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ö–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    tool_schemas = self.prepare_tool_schemas(tools) if tools else None
    
    # 3. –í—ã–∑–æ–≤ API –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    response = self.client.chat.completions.create(
        model=model_parameters.model,
        messages=provider_messages,
        tools=tool_schemas,
        temperature=model_parameters.temperature,
        max_tokens=model_parameters.max_tokens
    )
    
    # 4. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ LLMResponse
    return self.parse_response(response)
```

4. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**
```python
def supports_tool_calling(self, model_parameters: ModelParameters) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ function calling –¥–ª—è –º–æ–¥–µ–ª–∏"""
    tool_capable_models = ["gpt-4-turbo", "gpt-4o", "gpt-4o-mini"]
    return any(model in model_parameters.model for model in tool_capable_models)
```

## üéØ –ü–ª–∞–Ω –¥–ª—è Gemini Provider

### 1. –°–æ–∑–¥–∞—Ç—å GeminiClient
```python
class GeminiClient(BaseLLMClient):
    def __init__(self, model_parameters: ModelParameters):
        super().__init__(model_parameters)
        
        # API –∫–ª—é—á –∏–∑ env –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.api_key == "":
            self.api_key = os.getenv("GOOGLE_API_KEY", "")
            
        # –°–æ–∑–¥–∞–Ω–∏–µ Google Gemini –∫–ª–∏–µ–Ω—Ç–∞
        self.client = genai.Client(api_key=self.api_key)
        self.message_history = []
```

### 2. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
- `parse_messages()` - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è LLMMessage ‚Üí Gemini format
- `chat()` - –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å –≤—ã–∑–æ–≤–æ–º `client.models.generate_content()`
- `parse_response()` - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Gemini response ‚Üí LLMResponse
- `supports_tool_calling()` - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ function calling

### 3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ LLMClient
```python
# –í llm_client.py
class LLMProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic" 
    AZURE = "azure"
    GEMINI = "gemini"  # ‚ú® –î–æ–±–∞–≤–∏—Ç—å

# –í –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ LLMClient
elif provider == LLMProvider.GEMINI:
    from .gemini_client import GeminiClient
    self.client = GeminiClient(model_parameters)
```

## üîç –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è Gemini

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SDK**: `google-genai` —É–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç Pydantic –º–æ–¥–µ–ª–∏
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: Gemini response –ª–µ–≥–∫–æ –º–∞–ø–∏—Ç—Å—è –Ω–∞ LLMUsage
- **Function Calling**: –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–≤–∏–¥–µ–æ (–¥–ª—è –±—É–¥—É—â–µ–≥–æ)

### –í—ã–∑–æ–≤—ã
- **–§–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏–π**: –ù—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å `role` —Å–∏—Å—Ç–µ–º—É (user/assistant/model)
- **System Instructions**: Gemini –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
- **–¢–æ–∫–µ–Ω—ã thinking**: –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è Gemini 2.5 Flash

## üìÅ –§–∞–π–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è

1. `trae_agent/utils/gemini_client.py` - –û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
2. –û–±–Ω–æ–≤–∏—Ç—å `trae_agent/utils/llm_client.py` - –î–æ–±–∞–≤–∏—Ç—å GEMINI –ø—Ä–æ–≤–∞–π–¥–µ—Ä
3. –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é - –î–æ–±–∞–≤–∏—Ç—å Gemini –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ `trae_config.json`
4. –¢–µ—Å—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å Trae Agent

## ‚úÖ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- ‚úÖ **API –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω** - Gemini —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ
- ‚úÖ **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–∑—É—á–µ–Ω–∞** - –ü–∞—Ç—Ç–µ—Ä–Ω –ø–æ–Ω—è—Ç–µ–Ω
- ‚úÖ **–°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö** - –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞
- ‚úÖ **–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞** - .env –∏ —Ç–µ—Å—Ç—ã –≥–æ—Ç–æ–≤—ã

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –†–µ–∞–ª–∏–∑–∞—Ü–∏—è `GeminiClient` –ø–æ –æ–±—Ä–∞–∑—Ü—É `OpenAIClient`
